{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNH2dHWf2BLHjgKY2z97Zut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rydeveraumn/csci-5561-flying-dolphins/blob/main/DW_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Unzip the photos to a local Directory"
      ],
      "metadata": {
        "id": "Mk-TzljQJahQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Unzip photos to local directory\n",
        "!unzip /content/drive/MyDrive/Breast\\ Cancer\\ Data/preprocessed_pec_removal_240x384.zip -d /content/data\n"
      ],
      "metadata": {
        "id": "t2BQeRo9Jz44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get training csv\n"
      ],
      "metadata": {
        "id": "iipYiL8yLMex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Breast\\ Cancer\\ Data/train.csv.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6g8EpxVLRg5",
        "outputId": "246fa483-6389-482a-acfa-b840a660f3a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Breast Cancer Data/train.csv.zip\n",
            "  inflating: /content/train.csv      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model of DWS - CNN with Keras\n"
      ],
      "metadata": {
        "id": "5U8Q8tuoxpI9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vt1zVzqvvXmx"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import SeparableConv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "from keras.activations import relu\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "def weighted_binary_crossentropy(weights):\n",
        "    def loss(y_true, y_pred):\n",
        "        # Clip predictions to prevent log(0) error\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        # Calculate weighted binary cross entropy\n",
        "        loss = -(weights[0]*y_true*K.log(y_pred) + weights[1]*(1-y_true)*K.log(1-y_pred))\n",
        "        return K.mean(loss, axis=-1)\n",
        "    return loss\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Depthwise separable convolution -> Batch norm -> Max pooling\n",
        "model.add(SeparableConv2D(16, kernel_size=(2, 2), activation=relu, padding='same', input_shape=(12, 7, 512)))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Depthwise separable convolution -> Batch norm -> Depthwise separable convolution -> Batch norm -> Max pooling\n",
        "model.add(SeparableConv2D(32, kernel_size=(2, 2), activation=relu, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(SeparableConv2D(64, kernel_size=(2, 2), activation=relu, padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Depthwise separable convolution -> Batch norm -> Depthwise separable convolution -> Batch norm -> Depthwise separable convolution -> Batch norm -> Max pooling\n",
        "model.add(SeparableConv2D(64, kernel_size=(2, 2), activation=relu, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(SeparableConv2D(128, kernel_size=(2, 2), activation=relu, padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(SeparableConv2D(128, kernel_size=(2, 2), activation=relu, padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten and fully connected layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation=relu))\n",
        "model.add(Dense(64, activation=relu))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "#weights = [0.02, 0.98]\n",
        "#model.compile(optimizer='adam', loss=weighted_binary_crossentropy(weights), metrics=['accuracy', 'AUC'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Outline of training the model"
      ],
      "metadata": {
        "id": "6GypS4myXw2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "# Load dataset from CSV file\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Define paths to the image directory and labels\n",
        "img_dir = '/content/data/preprocessed_pec_removal_240x384'\n",
        "labels = data['cancer'].values\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=1)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    #image = tf.image.resize(image, [256, 256])\n",
        "    return image\n",
        "\n",
        "# Create a dataset of image paths and labels\n",
        "img_paths = [os.path.join(img_dir, '{}_{}.png'.format(pid, iid)) for pid, iid in zip(data['patient_id'], data['image_id'])]\n",
        "\n",
        "labels = data['cancer'].values\n",
        "\n",
        "images = np.zeros((labels.shape[0], 384, 240), dtype= np.int8)\n",
        "images = images[:15000]\n",
        "labels = labels[:15000]\n",
        "\n",
        "#Just test first 1000 for now\n",
        "for i in range(len(labels)):\n",
        "\n",
        "  images[i] = load_and_preprocess_image(img_paths[i])[:,:,0]\n",
        "\n",
        "\n",
        "# Split the data into train and test sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.5, stratify=labels)\n",
        "X_train = images[:int(len(labels)*0.8)]\n",
        "y_train = labels[:int(len(labels)*0.8)]\n",
        "X_test = images[int(len(labels)*0.8):]\n",
        "y_test = labels[int(len(labels)*0.8):]\n",
        "X_train = np.expand_dims(X_train, axis = -1)\n",
        "X_train = np.repeat(X_train, 3, axis = -1)\n",
        "X_test = np.expand_dims(X_test, axis = -1)\n",
        "X_test = np.repeat(X_test, 3, axis = -1)\n",
        "\n",
        "print(\"Extracting features\")\n",
        "# Extract features using a pre-trained CNN\n",
        "cnn = VGG16(weights='imagenet', include_top=False, input_shape=(384, 240, 3))\n",
        "train_features = cnn.predict(X_train)\n",
        "\n",
        "print(\"Train features Shape\")\n",
        "print(train_features.shape)\n",
        "\n",
        "\n",
        "# Flatten the features\n",
        "train_features_flat = np.reshape(train_features, (train_features.shape[0], -1))\n",
        "\n",
        "\n",
        "print(\"Train features flat Shape\")\n",
        "print(train_features_flat.shape)\n",
        "\n",
        "\n",
        "#Encode the labels\n",
        "le = LabelEncoder()\n",
        "train_labels = le.fit_transform(y_train)\n",
        "print(\"Train Labels Shape\")\n",
        "print(train_labels.shape)\n",
        "\n",
        "# Apply SMOTE to the feature space\n",
        "sm = SMOTE(sampling_strategy='minority')\n",
        "train_features_resampled, train_labels_resampled = sm.fit_resample(train_features_flat, train_labels)\n",
        "\n",
        "print(\"Train features resampled shape\")\n",
        "print(train_features_resampled.shape)\n",
        "\n",
        "# Reshape the features to their original shape\n",
        "train_features_resampled = np.reshape(train_features_resampled, (train_features_resampled.shape[0], 12, 7, 512))\n",
        "\n",
        "print(\"Train features resampled shape reshaped\")\n",
        "print(train_features_resampled.shape)\n",
        "\n",
        "#Get test set features\n",
        "test_features = cnn.predict(X_test)\n",
        "\n",
        "print(\"Test features Shape\")\n",
        "print(test_features.shape)\n",
        "\n",
        "# Flatten the features\n",
        "test_features_flat = np.reshape(test_features, (test_features.shape[0], -1))\n",
        "\n",
        "print(\"Test features flat Shape\")\n",
        "print(test_features_flat.shape)\n",
        "\n",
        "#Encode the labels\n",
        "le = LabelEncoder()\n",
        "test_labels = le.fit_transform(y_test)\n",
        "print(\"Test lables shape\")\n",
        "print(test_labels.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vzZQxiJiX1sv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358396c4-4570-4de2-83f2-0b6ddf984cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features\n",
            "Train features Shape\n",
            "Train features flat Shape\n",
            "Train Labels Shape\n",
            "(12000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "batch_size = 8\n",
        "num_epochs = 20\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Define the evaluation metric\n",
        "metrics = [tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", threshold=0.5), tf.keras.metrics.AUC(name='auc'), tf.keras.metrics.Precision(name = \"prec\"),  tf.keras.metrics.Recall(name = \"recal\"),tf.keras.metrics.TruePositives(name = \"tp\"), tf.keras.metrics.TrueNegatives(name = \"tn\"), tf.keras.metrics.FalsePositives(name = \"fp\"), tf.keras.metrics.FalseNegatives(name = \"fn\")]\n",
        "\n",
        "model.compile(optimizer = optimizer, loss = loss_fn, metrics = metrics)\n",
        "\n",
        "history = model.fit(train_features_resampled, train_labels_resampled, batch_size=batch_size, epochs=num_epochs, validation_data=(test_features, test_labels))\n",
        "\n",
        "#test_features, test_labels = next(iter((test_features, test_labels)))\n",
        "model.evaluate(test_features_flat, test_labels)\n",
        "\n",
        "\n",
        "model.save('/content/drive/MyDrive/CancerModelsTrained/CNNprelim')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQuq12C4o1_S",
        "outputId": "e4266f03-9a10-4205-99da-17f964748c1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2939/2939 [==============================] - 26s 8ms/step - loss: 0.6780 - binary_accuracy: 0.5740 - auc: 0.6065 - prec: 0.5640 - recal: 0.6526 - tp: 7670.0000 - tn: 5823.0000 - fp: 5930.0000 - fn: 4083.0000 - val_loss: 0.5622 - val_binary_accuracy: 0.5630 - val_auc: 0.5174 - val_prec: 0.0199 - val_recal: 0.4407 - val_tp: 26.0000 - val_tn: 1663.0000 - val_fp: 1278.0000 - val_fn: 33.0000\n",
            "Epoch 2/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.5433 - binary_accuracy: 0.6953 - auc: 0.7704 - prec: 0.6500 - recal: 0.8462 - tp: 9945.0000 - tn: 6399.0000 - fp: 5354.0000 - fn: 1808.0000 - val_loss: 0.6657 - val_binary_accuracy: 0.5673 - val_auc: 0.5271 - val_prec: 0.0224 - val_recal: 0.4915 - val_tp: 29.0000 - val_tn: 1673.0000 - val_fp: 1268.0000 - val_fn: 30.0000\n",
            "Epoch 3/20\n",
            "2939/2939 [==============================] - 20s 7ms/step - loss: 0.4489 - binary_accuracy: 0.7666 - auc: 0.8541 - prec: 0.7179 - recal: 0.8783 - tp: 10323.0000 - tn: 7697.0000 - fp: 4056.0000 - fn: 1430.0000 - val_loss: 0.5058 - val_binary_accuracy: 0.6800 - val_auc: 0.5126 - val_prec: 0.0233 - val_recal: 0.3729 - val_tp: 22.0000 - val_tn: 2018.0000 - val_fp: 923.0000 - val_fn: 37.0000\n",
            "Epoch 4/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.3787 - binary_accuracy: 0.8120 - auc: 0.8997 - prec: 0.7705 - recal: 0.8887 - tp: 10445.0000 - tn: 8641.0000 - fp: 3112.0000 - fn: 1308.0000 - val_loss: 0.4776 - val_binary_accuracy: 0.7133 - val_auc: 0.5271 - val_prec: 0.0238 - val_recal: 0.3390 - val_tp: 20.0000 - val_tn: 2120.0000 - val_fp: 821.0000 - val_fn: 39.0000\n",
            "Epoch 5/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.3294 - binary_accuracy: 0.8365 - auc: 0.9251 - prec: 0.7970 - recal: 0.9030 - tp: 10613.0000 - tn: 9050.0000 - fp: 2703.0000 - fn: 1140.0000 - val_loss: 0.5651 - val_binary_accuracy: 0.8653 - val_auc: 0.5492 - val_prec: 0.0350 - val_recal: 0.2203 - val_tp: 13.0000 - val_tn: 2583.0000 - val_fp: 358.0000 - val_fn: 46.0000\n",
            "Epoch 6/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.2940 - binary_accuracy: 0.8549 - auc: 0.9410 - prec: 0.8244 - recal: 0.9019 - tp: 10600.0000 - tn: 9495.0000 - fp: 2258.0000 - fn: 1153.0000 - val_loss: 0.4435 - val_binary_accuracy: 0.9013 - val_auc: 0.5435 - val_prec: 0.0460 - val_recal: 0.2034 - val_tp: 12.0000 - val_tn: 2692.0000 - val_fp: 249.0000 - val_fn: 47.0000\n",
            "Epoch 7/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.2732 - binary_accuracy: 0.8664 - auc: 0.9490 - prec: 0.8382 - recal: 0.9082 - tp: 10674.0000 - tn: 9692.0000 - fp: 2061.0000 - fn: 1079.0000 - val_loss: 0.5731 - val_binary_accuracy: 0.7420 - val_auc: 0.5316 - val_prec: 0.0265 - val_recal: 0.3390 - val_tp: 20.0000 - val_tn: 2206.0000 - val_fp: 735.0000 - val_fn: 39.0000\n",
            "Epoch 8/20\n",
            "2939/2939 [==============================] - 20s 7ms/step - loss: 0.2538 - binary_accuracy: 0.8743 - auc: 0.9559 - prec: 0.8445 - recal: 0.9175 - tp: 10783.0000 - tn: 9768.0000 - fp: 1985.0000 - fn: 970.0000 - val_loss: 0.6026 - val_binary_accuracy: 0.7723 - val_auc: 0.5674 - val_prec: 0.0301 - val_recal: 0.3390 - val_tp: 20.0000 - val_tn: 2297.0000 - val_fp: 644.0000 - val_fn: 39.0000\n",
            "Epoch 9/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.2418 - binary_accuracy: 0.8794 - auc: 0.9603 - prec: 0.8544 - recal: 0.9148 - tp: 10752.0000 - tn: 9920.0000 - fp: 1833.0000 - fn: 1001.0000 - val_loss: 0.4704 - val_binary_accuracy: 0.8067 - val_auc: 0.5639 - val_prec: 0.0289 - val_recal: 0.2712 - val_tp: 16.0000 - val_tn: 2404.0000 - val_fp: 537.0000 - val_fn: 43.0000\n",
            "Epoch 10/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.2337 - binary_accuracy: 0.8831 - auc: 0.9633 - prec: 0.8594 - recal: 0.9161 - tp: 10767.0000 - tn: 9992.0000 - fp: 1761.0000 - fn: 986.0000 - val_loss: 0.5889 - val_binary_accuracy: 0.7797 - val_auc: 0.5507 - val_prec: 0.0282 - val_recal: 0.3051 - val_tp: 18.0000 - val_tn: 2321.0000 - val_fp: 620.0000 - val_fn: 41.0000\n",
            "Epoch 11/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.2189 - binary_accuracy: 0.8904 - auc: 0.9673 - prec: 0.8636 - recal: 0.9273 - tp: 10898.0000 - tn: 10032.0000 - fp: 1721.0000 - fn: 855.0000 - val_loss: 0.6521 - val_binary_accuracy: 0.8060 - val_auc: 0.5451 - val_prec: 0.0288 - val_recal: 0.2712 - val_tp: 16.0000 - val_tn: 2402.0000 - val_fp: 539.0000 - val_fn: 43.0000\n",
            "Epoch 12/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.2111 - binary_accuracy: 0.8890 - auc: 0.9693 - prec: 0.8665 - recal: 0.9198 - tp: 10810.0000 - tn: 10087.0000 - fp: 1666.0000 - fn: 943.0000 - val_loss: 0.6745 - val_binary_accuracy: 0.7823 - val_auc: 0.5584 - val_prec: 0.0286 - val_recal: 0.3051 - val_tp: 18.0000 - val_tn: 2329.0000 - val_fp: 612.0000 - val_fn: 41.0000\n",
            "Epoch 13/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.2131 - binary_accuracy: 0.8898 - auc: 0.9687 - prec: 0.8670 - recal: 0.9209 - tp: 10823.0000 - tn: 10093.0000 - fp: 1660.0000 - fn: 930.0000 - val_loss: 0.6327 - val_binary_accuracy: 0.7767 - val_auc: 0.5576 - val_prec: 0.0264 - val_recal: 0.2881 - val_tp: 17.0000 - val_tn: 2313.0000 - val_fp: 628.0000 - val_fn: 42.0000\n",
            "Epoch 14/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.2009 - binary_accuracy: 0.8957 - auc: 0.9719 - prec: 0.8721 - recal: 0.9274 - tp: 10900.0000 - tn: 10154.0000 - fp: 1599.0000 - fn: 853.0000 - val_loss: 0.6986 - val_binary_accuracy: 0.7883 - val_auc: 0.5810 - val_prec: 0.0294 - val_recal: 0.3051 - val_tp: 18.0000 - val_tn: 2347.0000 - val_fp: 594.0000 - val_fn: 41.0000\n",
            "Epoch 15/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.1933 - binary_accuracy: 0.8993 - auc: 0.9738 - prec: 0.8797 - recal: 0.9251 - tp: 10873.0000 - tn: 10266.0000 - fp: 1487.0000 - fn: 880.0000 - val_loss: 0.7306 - val_binary_accuracy: 0.9370 - val_auc: 0.5677 - val_prec: 0.0548 - val_recal: 0.1356 - val_tp: 8.0000 - val_tn: 2803.0000 - val_fp: 138.0000 - val_fn: 51.0000\n",
            "Epoch 16/20\n",
            "2939/2939 [==============================] - 20s 7ms/step - loss: 0.1931 - binary_accuracy: 0.9005 - auc: 0.9741 - prec: 0.8794 - recal: 0.9282 - tp: 10909.0000 - tn: 10257.0000 - fp: 1496.0000 - fn: 844.0000 - val_loss: 0.6714 - val_binary_accuracy: 0.8133 - val_auc: 0.5608 - val_prec: 0.0282 - val_recal: 0.2542 - val_tp: 15.0000 - val_tn: 2425.0000 - val_fp: 516.0000 - val_fn: 44.0000\n",
            "Epoch 17/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.1861 - binary_accuracy: 0.9020 - auc: 0.9756 - prec: 0.8753 - recal: 0.9375 - tp: 11019.0000 - tn: 10183.0000 - fp: 1570.0000 - fn: 734.0000 - val_loss: 0.7602 - val_binary_accuracy: 0.8150 - val_auc: 0.5627 - val_prec: 0.0231 - val_recal: 0.2034 - val_tp: 12.0000 - val_tn: 2433.0000 - val_fp: 508.0000 - val_fn: 47.0000\n",
            "Epoch 18/20\n",
            "2939/2939 [==============================] - 20s 7ms/step - loss: 0.1811 - binary_accuracy: 0.9050 - auc: 0.9768 - prec: 0.8775 - recal: 0.9414 - tp: 11064.0000 - tn: 10208.0000 - fp: 1545.0000 - fn: 689.0000 - val_loss: 0.7390 - val_binary_accuracy: 0.7757 - val_auc: 0.5305 - val_prec: 0.0291 - val_recal: 0.3220 - val_tp: 19.0000 - val_tn: 2308.0000 - val_fp: 633.0000 - val_fn: 40.0000\n",
            "Epoch 19/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.1767 - binary_accuracy: 0.9037 - auc: 0.9773 - prec: 0.8798 - recal: 0.9352 - tp: 10991.0000 - tn: 10252.0000 - fp: 1501.0000 - fn: 762.0000 - val_loss: 0.7356 - val_binary_accuracy: 0.7937 - val_auc: 0.5588 - val_prec: 0.0238 - val_recal: 0.2373 - val_tp: 14.0000 - val_tn: 2367.0000 - val_fp: 574.0000 - val_fn: 45.0000\n",
            "Epoch 20/20\n",
            "2939/2939 [==============================] - 21s 7ms/step - loss: 0.1769 - binary_accuracy: 0.9085 - auc: 0.9784 - prec: 0.8874 - recal: 0.9358 - tp: 10999.0000 - tn: 10357.0000 - fp: 1396.0000 - fn: 754.0000 - val_loss: 0.5386 - val_binary_accuracy: 0.9417 - val_auc: 0.5516 - val_prec: 0.0397 - val_recal: 0.0847 - val_tp: 5.0000 - val_tn: 2820.0000 - val_fp: 121.0000 - val_fn: 54.0000\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.5386 - binary_accuracy: 0.9417 - auc: 0.5516 - prec: 0.0397 - recal: 0.0847 - tp: 5.0000 - tn: 2820.0000 - fp: 121.0000 - fn: 54.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2us7AYBHTlZp"
      }
    }
  ]
}